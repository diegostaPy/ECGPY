{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "going-theory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant: 1/25\n",
      "  - Condition 1/5\n",
      "  - Condition 2/5\n",
      "  - Condition 3/5\n",
      "  - Condition 4/5\n",
      "  - Condition 5/5\n",
      "Participant: 2/25\n",
      "  - Condition 1/5\n",
      "  - Condition 2/5\n",
      "  - Condition 3/5\n",
      "  - Condition 4/5\n",
      "  - Condition 5/5\n",
      "Participant: 3/25\n",
      "  - Condition 1/5\n",
      "  - Condition 2/5\n",
      "  - Condition 3/5\n",
      "  - Condition 4/5\n",
      "  - Condition 5/5\n",
      "Participant: 4/25\n",
      "  - Condition 1/5\n",
      "  - Condition 2/5\n",
      "  - Condition 3/5\n",
      "  - Condition 4/5\n",
      "  - Condition 5/5\n",
      "Participant: 5/25\n",
      "  - Condition 1/5\n",
      "  - Condition 2/5\n",
      "  - Condition 3/5\n",
      "  - Condition 4/5\n",
      "  - Condition 5/5\n",
      "Participant: 6/25\n",
      "  - Condition 1/5\n",
      "  - Condition 2/5\n",
      "  - Condition 3/5\n",
      "  - Condition 4/5\n",
      "  - Condition 5/5\n",
      "Participant: 7/25\n",
      "  - Condition 1/5\n",
      "  - Condition 2/5\n",
      "  - Condition 3/5\n",
      "  - Condition 4/5\n",
      "  - Condition 5/5\n",
      "Participant: 8/25\n",
      "  - Condition 1/5\n",
      "  - Condition 2/5\n",
      "  - Condition 3/5\n",
      "  - Condition 4/5\n",
      "  - Condition 5/5\n",
      "Participant: 9/25\n",
      "  - Condition 1/5\n",
      "  - Condition 2/5\n",
      "  - Condition 3/5\n",
      "  - Condition 4/5\n",
      "  - Condition 5/5\n",
      "Participant: 10/25\n",
      "  - Condition 1/5\n",
      "  - Condition 2/5\n",
      "  - Condition 3/5\n",
      "  - Condition 4/5\n",
      "  - Condition 5/5\n",
      "Participant: 11/25\n",
      "  - Condition 1/5\n",
      "  - Condition 2/5\n",
      "  - Condition 3/5\n",
      "  - Condition 4/5\n",
      "  - Condition 5/5\n",
      "Participant: 12/25\n",
      "  - Condition 1/5\n",
      "  - Condition 2/5\n",
      "  - Condition 3/5\n",
      "  - Condition 4/5\n",
      "  - Condition 5/5\n",
      "Participant: 13/25\n",
      "  - Condition 1/5\n",
      "  - Condition 2/5\n",
      "  - Condition 3/5\n",
      "  - Condition 4/5\n",
      "  - Condition 5/5\n",
      "Participant: 14/25\n",
      "  - Condition 1/5\n",
      "  - Condition 2/5\n",
      "  - Condition 3/5\n",
      "  - Condition 4/5\n",
      "  - Condition 5/5\n",
      "Participant: 15/25\n",
      "  - Condition 1/5\n",
      "  - Condition 2/5\n",
      "  - Condition 3/5\n",
      "  - Condition 4/5\n",
      "  - Condition 5/5\n",
      "Participant: 16/25\n",
      "  - Condition 1/5\n",
      "  - Condition 2/5\n",
      "  - Condition 3/5\n",
      "  - Condition 4/5\n",
      "  - Condition 5/5\n",
      "Participant: 17/25\n",
      "  - Condition 1/5\n",
      "  - Condition 2/5\n",
      "  - Condition 3/5\n",
      "  - Condition 4/5\n",
      "  - Condition 5/5\n",
      "Participant: 18/25\n",
      "  - Condition 1/5\n",
      "  - Condition 2/5\n",
      "  - Condition 3/5\n",
      "  - Condition 4/5\n",
      "  - Condition 5/5\n",
      "Participant: 19/25\n",
      "  - Condition 1/5\n",
      "  - Condition 2/5\n",
      "  - Condition 3/5\n",
      "  - Condition 4/5\n",
      "  - Condition 5/5\n",
      "Participant: 20/25\n",
      "  - Condition 1/5\n",
      "  - Condition 2/5\n",
      "  - Condition 3/5\n",
      "  - Condition 4/5\n",
      "  - Condition 5/5\n",
      "Participant: 21/25\n",
      "  - Condition 1/5\n",
      "  - Condition 2/5\n",
      "  - Condition 3/5\n",
      "  - Condition 4/5\n",
      "  - Condition 5/5\n",
      "Participant: 22/25\n",
      "  - Condition 1/5\n",
      "  - Condition 2/5\n",
      "  - Condition 3/5\n",
      "  - Condition 4/5\n",
      "  - Condition 5/5\n",
      "Participant: 23/25\n",
      "  - Condition 1/5\n",
      "  - Condition 2/5\n",
      "  - Condition 3/5\n",
      "  - Condition 4/5\n",
      "  - Condition 5/5\n",
      "Participant: 24/25\n",
      "  - Condition 1/5\n",
      "  - Condition 2/5\n",
      "  - Condition 3/5\n",
      "  - Condition 4/5\n",
      "  - Condition 5/5\n",
      "Participant: 25/25\n",
      "  - Condition 1/5\n",
      "  - Condition 2/5\n",
      "  - Condition 3/5\n",
      "  - Condition 4/5\n",
      "  - Condition 5/5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ecg_gudb_database\n",
    "\n",
    "\n",
    "dfs_ecg = []\n",
    "dfs_rpeaks = []\n",
    "\n",
    "for participant in range(25):\n",
    "    print(\"Participant: \" + str(participant+1) + \"/25\")\n",
    "    for i, experiment in enumerate(ecg_gudb_database.GUDb.experiments):\n",
    "        print(\"  - Condition \" + str(i+1) + \"/5\")\n",
    "        # creating class which loads the experiment\n",
    "        ecg_class = ecg_gudb_database.GUDb(participant, experiment)\n",
    "\n",
    "        # Chest Strap Data - only donwload if R-peaks annotations are available\n",
    "        if ecg_class.anno_cs_exists:\n",
    "\n",
    "            data = pd.DataFrame({\"ECG\": ecg_class.cs_V2_V1})\n",
    "            data[\"Participant\"] = \"GUDB_%.2i\" %(participant)\n",
    "            data[\"Sample\"] = range(len(data))\n",
    "            data[\"Sampling_Rate\"] = 250\n",
    "            data[\"Database\"] = \"GUDB_\" + experiment\n",
    "\n",
    "            # getting annotations\n",
    "            anno = pd.DataFrame({\"Rpeaks\": ecg_class.anno_cs})\n",
    "            anno[\"Participant\"] = \"GUDB_%.2i\" %(participant)\n",
    "            anno[\"Sampling_Rate\"] = 250\n",
    "            anno[\"Database\"] = \"GUDB (\" + experiment + \")\"\n",
    "\n",
    "            # Store with the rest\n",
    "            dfs_ecg.append(data)\n",
    "            dfs_rpeaks.append(anno)\n",
    "\n",
    "        # Einthoven leads\n",
    "#        if ecg_class.anno_cables_exists:\n",
    "#            cables_anno = ecg_class.anno_cables\n",
    "#            einthoven_i = ecg_class.einthoven_I\n",
    "#            einthoven_ii = ecg_class.einthoven_II\n",
    "#            einthoven_iii = ecg_class.einthoven_III\n",
    "\n",
    "\n",
    "\n",
    "# Save\n",
    "df_ecg = pd.concat(dfs_ecg).to_csv(\"ECGs.csv\", index=False)\n",
    "dfs_rpeaks = pd.concat(dfs_rpeaks).to_csv(\"Rpeaks.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "celtic-brazilian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant: 1/48\n",
      "Participant: 2/48\n",
      "Participant: 3/48\n",
      "Participant: 4/48\n",
      "Participant: 5/48\n",
      "Participant: 6/48\n",
      "Participant: 7/48\n",
      "Participant: 8/48\n",
      "Participant: 9/48\n",
      "  - Additional recording detected.\n",
      "Participant: 10/48\n",
      "  - Additional recording detected.\n",
      "Participant: 11/48\n",
      "  - Additional recording detected.\n",
      "Participant: 12/48\n",
      "  - Additional recording detected.\n",
      "Participant: 13/48\n",
      "  - Additional recording detected.\n",
      "Participant: 14/48\n",
      "  - Additional recording detected.\n",
      "Participant: 15/48\n",
      "  - Additional recording detected.\n",
      "Participant: 16/48\n",
      "  - Additional recording detected.\n",
      "Participant: 17/48\n",
      "  - Additional recording detected.\n",
      "Participant: 18/48\n",
      "Participant: 19/48\n",
      "Participant: 20/48\n",
      "  - Additional recording detected.\n",
      "Participant: 21/48\n",
      "  - Additional recording detected.\n",
      "Participant: 22/48\n",
      "  - Additional recording detected.\n",
      "Participant: 23/48\n",
      "  - Additional recording detected.\n",
      "Participant: 24/48\n",
      "Participant: 25/48\n",
      "Participant: 26/48\n",
      "Participant: 27/48\n",
      "Participant: 28/48\n",
      "Participant: 29/48\n",
      "Participant: 30/48\n",
      "Participant: 31/48\n",
      "Participant: 32/48\n",
      "Participant: 33/48\n",
      "Participant: 34/48\n",
      "Participant: 35/48\n",
      "Participant: 36/48\n",
      "Participant: 37/48\n",
      "Participant: 38/48\n",
      "Participant: 39/48\n",
      "  - Additional recording detected.\n",
      "Participant: 40/48\n",
      "  - Additional recording detected.\n",
      "Participant: 41/48\n",
      "  - Additional recording detected.\n",
      "Participant: 42/48\n",
      "  - Additional recording detected.\n",
      "Participant: 43/48\n",
      "  - Additional recording detected.\n",
      "Participant: 44/48\n",
      "  - Additional recording detected.\n",
      "Participant: 45/48\n",
      "  - Additional recording detected.\n",
      "Participant: 46/48\n",
      "  - Additional recording detected.\n",
      "Participant: 47/48\n",
      "  - Additional recording detected.\n",
      "Participant: 48/48\n",
      "  - Additional recording detected.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wfdb\n",
    "import os\n",
    "folder=\"datasets/\"\n",
    "data_files = [folder+\"mit-bih-arrhythmia-database-1.0.0/\" + file for file in os.listdir(folder+\"mit-bih-arrhythmia-database-1.0.0\") if \".dat\" in file]\n",
    "\n",
    "\n",
    "def read_file(file, participant):\n",
    "    \"\"\"Utility function\n",
    "    \"\"\"\n",
    "    # Get signal\n",
    "    data = pd.DataFrame({\"ECG\": wfdb.rdsamp(file[:-4])[0][:, 0]})\n",
    "    data[\"Participant\"] = \"MIT-Arrhythmia_%.2i\" %(participant)\n",
    "    data[\"Sample\"] = range(len(data))\n",
    "    data[\"Sampling_Rate\"] = 360\n",
    "    data[\"Database\"] = \"MIT-Arrhythmia-x\" if \"x_mitdb\" in file else \"MIT-Arrhythmia\"\n",
    "\n",
    "    # getting annotations\n",
    "    anno = wfdb.rdann(file[:-4], 'atr')\n",
    "    anno = np.unique(anno.sample[np.in1d(anno.symbol, ['N', 'L', 'R', 'B', 'A', 'a', 'J', 'S', 'V', 'r', 'F', 'e', 'j', 'n', 'E', '/', 'f', 'Q', '?'])])\n",
    "    anno = pd.DataFrame({\"Rpeaks\": anno})\n",
    "    anno[\"Participant\"] = \"MIT-Arrhythmia_%.2i\" %(participant)\n",
    "    anno[\"Sampling_Rate\"] = 360\n",
    "    anno[\"Database\"] = \"MIT-Arrhythmia-x\" if \"x_mitdb\" in file else \"MIT-Arrhythmia\"\n",
    "\n",
    "    return data, anno\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dfs_ecg = []\n",
    "dfs_rpeaks = []\n",
    "\n",
    "for participant, file in enumerate(data_files):\n",
    "\n",
    "    print(\"Participant: \" + str(participant + 1) + \"/\" + str(len(data_files)))\n",
    "\n",
    "    data, anno = read_file(file, participant)\n",
    "\n",
    "    # Store with the rest\n",
    "    dfs_ecg.append(data)\n",
    "    dfs_rpeaks.append(anno)\n",
    "\n",
    "    # Store additional recording if available\n",
    "    if \"x_\" + file.replace(folder+\"mit-bih-arrhythmia-database-1.0.0/\", \"\") in os.listdir(folder+\"mit-bih-arrhythmia-database-1.0.0/x_mitdb/\"):\n",
    "        print(\"  - Additional recording detected.\")\n",
    "        data, anno = read_file(folder+\"mit-bih-arrhythmia-database-1.0.0/x_mitdb/\" + \"x_\" + file.replace(folder+\"mit-bih-arrhythmia-database-1.0.0/\", \"\"), participant)\n",
    "        # Store with the rest\n",
    "        dfs_ecg.append(data)\n",
    "        dfs_rpeaks.append(anno)\n",
    "\n",
    "\n",
    "\n",
    "# Save\n",
    "#df_ecg = pd.concat(dfs_ecg).to_csv(\"ECGs.csv\", index=False)\n",
    "#dfs_rpeaks = pd.concat(dfs_rpeaks).to_csv(\"Rpeaks.csv\", index=False)\n",
    "\n",
    "# Quick test\n",
    "#import neurokit2 as nk\n",
    "#nk.events_plot(anno[\"Rpeaks\"][anno[\"Rpeaks\"] <= 1000], data[\"ECG\"][0:1002])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "accomplished-scene",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ecg = pd.concat(dfs_ecg).to_csv(\"datasetsCSV/mit_arrhythmia/ECGs.csv\", index=False)\n",
    "dfs_rpeaks = pd.concat(dfs_rpeaks).to_csv(\"datasetsCSV/mit_arrhythmia/Rpeaks.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cordless-hardwood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant: 1/18\n",
      "Participant: 2/18\n",
      "Participant: 3/18\n",
      "Participant: 4/18\n",
      "Participant: 5/18\n",
      "Participant: 6/18\n",
      "Participant: 7/18\n",
      "Participant: 8/18\n",
      "Participant: 9/18\n",
      "Participant: 10/18\n",
      "Participant: 11/18\n",
      "Participant: 12/18\n",
      "Participant: 13/18\n",
      "Participant: 14/18\n",
      "Participant: 15/18\n",
      "Participant: 16/18\n",
      "Participant: 17/18\n",
      "Participant: 18/18\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wfdb\n",
    "import os\n",
    "folder=\"datasets/\"\n",
    "data_files = [folder+\"mit-bih-normal-sinus-rhythm-database-1.0.0/\" + file for file in os.listdir(folder+\"mit-bih-normal-sinus-rhythm-database-1.0.0\") if \".dat\" in file]\n",
    "\n",
    "\n",
    "\n",
    "dfs_ecg = []\n",
    "dfs_rpeaks = []\n",
    "\n",
    "for participant, file in enumerate(data_files):\n",
    "\n",
    "    print(\"Participant: \" + str(participant + 1) + \"/\" + str(len(data_files)))\n",
    "\n",
    "\n",
    "    # Get signal\n",
    "    data = pd.DataFrame({\"ECG\": wfdb.rdsamp(file[:-4])[0][:, 1]})\n",
    "    data[\"Participant\"] = \"MIT-Normal_%.2i\" %(participant)\n",
    "    data[\"Sample\"] = range(len(data))\n",
    "    data[\"Sampling_Rate\"] = 128\n",
    "    data[\"Database\"] = \"MIT-Normal\"\n",
    "\n",
    "    # getting annotations\n",
    "    anno = wfdb.rdann(file[:-4], 'atr')\n",
    "    anno = anno.sample[np.where(np.array(anno.symbol) == \"N\")[0]]\n",
    "    anno = pd.DataFrame({\"Rpeaks\": anno})\n",
    "    anno[\"Participant\"] = \"MIT-Normal_%.2i\" %(participant)\n",
    "    anno[\"Sampling_Rate\"] = 128\n",
    "    anno[\"Database\"] = \"MIT-Normal\"\n",
    "\n",
    "    # Select only 1h of recording (otherwise it's too big)\n",
    "    data = data[460800:460800*3].reset_index(drop=True)\n",
    "    anno = anno[(anno[\"Rpeaks\"] > 460800) & (anno[\"Rpeaks\"] <= 460800*2)].reset_index(drop=True)\n",
    "    anno[\"Rpeaks\"] = anno[\"Rpeaks\"] - 460800\n",
    "\n",
    "\n",
    "    # Store with the rest\n",
    "    dfs_ecg.append(data)\n",
    "    dfs_rpeaks.append(anno)\n",
    "\n",
    "\n",
    "\n",
    "# Save\n",
    "df_ecg = pd.concat(dfs_ecg).to_csv(\"datasetsCSV/mit_normal/ECGs.csv\", index=False)\n",
    "dfs_rpeaks = pd.concat(dfs_rpeaks).to_csv(\"datasetsCSV/mit_normal/Rpeaks.csv\", index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "experimental-pocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wfdb\n",
    "import os\n",
    "\n",
    "\n",
    "files = os.listdir(\"datasets/fantasia-database-1.0.0/\")\n",
    "files = [s.replace('.dat', '') for s in files if \".dat\" in s]\n",
    "\n",
    "dfs_ecg = []\n",
    "dfs_rpeaks = []\n",
    "\n",
    "\n",
    "for i, participant in enumerate(files):\n",
    "\n",
    "    data, info = wfdb.rdsamp(\"datasets/fantasia-database-1.0.0/\" + participant)\n",
    "\n",
    "    # Get signal\n",
    "    data = pd.DataFrame(data, columns=info[\"sig_name\"])\n",
    "    data = data[[\"ECG\"]]\n",
    "    data[\"Participant\"] = \"Fantasia_\" + participant\n",
    "    data[\"Sample\"] = range(len(data))\n",
    "    data[\"Sampling_Rate\"] = info['fs']\n",
    "    data[\"Database\"] = \"Fantasia\"\n",
    "\n",
    "    # Get annotations\n",
    "    anno = wfdb.rdann(\"datasets/fantasia-database-1.0.0/\" + participant, 'ecg')\n",
    "    anno = anno.sample[np.where(np.array(anno.symbol) == \"N\")[0]]\n",
    "    anno = pd.DataFrame({\"Rpeaks\": anno})\n",
    "    anno[\"Participant\"] = \"Fantasia_\" + participant\n",
    "    anno[\"Sampling_Rate\"] = info['fs']\n",
    "    anno[\"Database\"] = \"Fantasia\"\n",
    "\n",
    "    # Store with the rest\n",
    "    dfs_ecg.append(data)\n",
    "    dfs_rpeaks.append(anno)\n",
    "\n",
    "\n",
    "# Save\n",
    "df_ecg = pd.concat(dfs_ecg).to_csv(\"datasetsCSV/fantasia/ECGs.csv\", index=False)\n",
    "dfs_rpeaks = pd.concat(dfs_rpeaks).to_csv(\"datasetsCSV/fantasia/Rpeaks.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "incorporated-colombia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gsutil\n",
      "  Downloading gsutil-5.21.tar.gz (3.0 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -utopep8 (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lake8 (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -utopep8 (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lake8 (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -utopep8 (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lake8 (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -utopep8 (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -umpy (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -lake8 (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -ip (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -illow (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -cikit-learn (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -utopep8 (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lake8 (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ---------------------------------------- 3.0/3.0 MB 2.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting argcomplete>=1.9.4\n",
      "  Downloading argcomplete-3.0.5-py3-none-any.whl (40 kB)\n",
      "     ---------------------------------------- 40.2/40.2 kB 1.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: crcmod>=1.7 in d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages (from gsutil) (1.7)\n",
      "Collecting fasteners>=0.14.1\n",
      "  Downloading fasteners-0.18-py3-none-any.whl (18 kB)\n",
      "Collecting gcs-oauth2-boto-plugin>=3.0\n",
      "  Downloading gcs-oauth2-boto-plugin-3.0.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting google-apitools>=0.5.32\n",
      "  Downloading google_apitools-0.5.32-py3-none-any.whl (135 kB)\n",
      "     -------------------------------------- 135.7/135.7 kB 7.8 MB/s eta 0:00:00\n",
      "Collecting httplib2==0.20.4\n",
      "  Downloading httplib2-0.20.4-py3-none-any.whl (96 kB)\n",
      "     ---------------------------------------- 96.6/96.6 kB 5.4 MB/s eta 0:00:00\n",
      "Collecting google-reauth>=0.1.0\n",
      "  Downloading google_reauth-0.1.1-py2.py3-none-any.whl (17 kB)\n",
      "Collecting monotonic>=1.4\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: pyOpenSSL>=0.13 in d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages (from gsutil) (20.0.1)\n",
      "Collecting retry_decorator>=1.0.0\n",
      "  Downloading retry_decorator-1.1.1.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages (from gsutil) (1.15.0)\n",
      "Collecting google-auth[aiohttp]>=2.5.0\n",
      "  Downloading google_auth-2.17.1-py2.py3-none-any.whl (178 kB)\n",
      "     -------------------------------------- 178.1/178.1 kB 5.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages (from httplib2==0.20.4->gsutil) (2.4.7)\n",
      "Requirement already satisfied: rsa==4.7.2 in d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages (from gcs-oauth2-boto-plugin>=3.0->gsutil) (4.7.2)\n",
      "Collecting boto>=2.29.1\n",
      "  Downloading boto-2.49.0-py2.py3-none-any.whl (1.4 MB)\n",
      "     ---------------------------------------- 1.4/1.4 MB 4.8 MB/s eta 0:00:00\n",
      "Collecting oauth2client>=2.2.0\n",
      "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "     ---------------------------------------- 98.2/98.2 kB 5.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages (from rsa==4.7.2->gcs-oauth2-boto-plugin>=3.0->gsutil) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages (from google-auth[aiohttp]>=2.5.0->gsutil) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages (from google-auth[aiohttp]>=2.5.0->gsutil) (4.2.1)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.20.0 in d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages (from google-auth[aiohttp]>=2.5.0->gsutil) (2.25.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0dev,>=3.6.2 in c:\\users\\yoda\\appdata\\roaming\\python\\python38\\site-packages (from google-auth[aiohttp]>=2.5.0->gsutil) (3.8.1)\n",
      "Collecting pyu2f\n",
      "  Downloading pyu2f-0.1.5.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: cryptography>=3.2 in d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages (from pyOpenSSL>=0.13->gsutil) (3.3.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\yoda\\appdata\\roaming\\python\\python38\\site-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\yoda\\appdata\\roaming\\python\\python38\\site-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil) (2.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\yoda\\appdata\\roaming\\python\\python38\\site-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\yoda\\appdata\\roaming\\python\\python38\\site-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\yoda\\appdata\\roaming\\python\\python38\\site-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil) (1.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil) (20.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\yoda\\appdata\\roaming\\python\\python38\\site-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth[aiohttp]>=2.5.0->gsutil) (1.7.2)\n",
      "Requirement already satisfied: cffi>=1.12 in d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages (from cryptography>=3.2->pyOpenSSL>=0.13->gsutil) (1.14.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages (from requests<3.0.0dev,>=2.20.0->google-auth[aiohttp]>=2.5.0->gsutil) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages (from requests<3.0.0dev,>=2.20.0->google-auth[aiohttp]>=2.5.0->gsutil) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages (from requests<3.0.0dev,>=2.20.0->google-auth[aiohttp]>=2.5.0->gsutil) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages (from requests<3.0.0dev,>=2.20.0->google-auth[aiohttp]>=2.5.0->gsutil) (1.26.3)\n",
      "Requirement already satisfied: pycparser in d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages (from cffi>=1.12->cryptography>=3.2->pyOpenSSL>=0.13->gsutil) (2.20)\n",
      "Building wheels for collected packages: gsutil, gcs-oauth2-boto-plugin, retry_decorator, pyu2f\n",
      "  Building wheel for gsutil (setup.py): started\n",
      "  Building wheel for gsutil (setup.py): finished with status 'done'\n",
      "  Created wheel for gsutil: filename=gsutil-5.21-py3-none-any.whl size=3786575 sha256=5f8a56298098f8c4dbed765f8d1a1ed182da6ad3febac81ee57f89b25150feee\n",
      "  Stored in directory: c:\\users\\yoda\\appdata\\local\\pip\\cache\\wheels\\15\\77\\97\\729c40c3202c5fb628b8c618a64d2dc84e325b9e8d75266c3f\n",
      "  Building wheel for gcs-oauth2-boto-plugin (setup.py): started\n",
      "  Building wheel for gcs-oauth2-boto-plugin (setup.py): finished with status 'done'\n",
      "  Created wheel for gcs-oauth2-boto-plugin: filename=gcs_oauth2_boto_plugin-3.0-py3-none-any.whl size=23220 sha256=a124ecda3e7e38ea17af6fadce5bd074addae931a94427ff62c20b285e03640c\n",
      "  Stored in directory: c:\\users\\yoda\\appdata\\local\\pip\\cache\\wheels\\66\\83\\78\\02eaa0db6575dc1d531a6accf66cb382dd3a8a494b6f0aec10\n",
      "  Building wheel for retry_decorator (setup.py): started\n",
      "  Building wheel for retry_decorator (setup.py): finished with status 'done'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -utopep8 (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lake8 (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -utopep8 (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lake8 (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -utopep8 (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -lake8 (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -utopep8 (d:\\userfiles\\anaconda\\envs\\ia\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install gsutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "maritime-channel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wfdb\n",
    "import os\n",
    "\n",
    "\n",
    "files = os.listdir(\"datasets/ludb1/\")\n",
    "\n",
    "dfs_ecg = []\n",
    "dfs_rpeaks = []\n",
    "\n",
    "\n",
    "for participant in range(200):\n",
    "    filename = str(participant + 1)\n",
    "\n",
    "    data, info = wfdb.rdsamp(\"datasets/ludb1/data/\" + filename)\n",
    "\n",
    "    # Get signal\n",
    "    data = pd.DataFrame(data, columns=info[\"sig_name\"])\n",
    "    data = data[[\"i\"]].rename(columns={\"i\": \"ECG\"})\n",
    "    data[\"Participant\"] = \"LUDB_%.2i\" %(participant + 1)\n",
    "    data[\"Sample\"] = range(len(data))\n",
    "    data[\"Sampling_Rate\"] = info['fs']\n",
    "    data[\"Database\"] = \"LUDB\"\n",
    "\n",
    "    # Get annotations\n",
    "    anno = wfdb.rdann(\"datasets/ludb1/data/\" + filename, 'i')\n",
    "    anno = anno.sample[np.where(np.array(anno.symbol) == \"N\")[0]]\n",
    "    anno = pd.DataFrame({\"Rpeaks\": anno})\n",
    "    anno[\"Participant\"] = \"LUDB_%.2i\" %(participant + 1)\n",
    "    anno[\"Sampling_Rate\"] = info['fs']\n",
    "    anno[\"Database\"] = \"LUDB\"\n",
    "\n",
    "    # Store with the rest\n",
    "    dfs_ecg.append(data)\n",
    "    dfs_rpeaks.append(anno)\n",
    "\n",
    "\n",
    "# Save\n",
    "df_ecg = pd.concat(dfs_ecg).to_csv(\"datasetsCSV/ludb/ECGs.csv\", index=False)\n",
    "dfs_rpeaks = pd.concat(dfs_rpeaks).to_csv(\"datasetsCSV/ludb/Rpeaks.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-straight",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
